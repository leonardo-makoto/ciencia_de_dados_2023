---
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# MAE 5905: Introdução à Ciência de Dados

## Prova 1. Primeiro Semestre de 2023. Entregar 19/05/2023.

Aluno: Leonardo Makoto Kawahara - 7180679

```{r preliminares, echo=TRUE, message=FALSE, warning=FALSE, results=FALSE}
set.seed(1)
library(tidyverse)
library(MASS)
library(ISLR)
library(caret)
library(glmnet)
library(ggplot2)

```

# Exercício 1

## Item 1a

Considere o caso de duas populações exponenciais, uma com média 1 e outra com média 0,5. Supondo $\pi_1$ = $\pi_2$, encontre o classificador de Bayes. Quais são as probabilidades de classificação incorreta? Construa um gráfico, mostrando a fronteira de decisão e as regiões de classificação em cada população. Generalize para o caso das médias serem $\alpha > 0$ e $\beta > 0$, respectivamente.

### Resposta:

Sejam $X_1$ e $X_2$ variáveis aleatórias com média 1 e média 0,5, respectivamente. Temos que \begin{equation}
f(x_1;\lambda_1)=
\begin{cases}
\lambda_1 e^{-\lambda_1 x}, & \text{se}\ x_1 \geq 0 \\
0, & \text{caso contrário}
\end{cases}
\\
f(x_2;\lambda_2)=
\begin{cases}
\lambda_2 e^{-\lambda_2 x}, & \text{se}\ x_2 \geq 0 \\
0, & \text{caso contrário}
\end{cases}
\end{equation}

Como a $E(X_1) = 1$ e $E(X_2) = 0,1$, temos que $\lambda_1 = 1$ e $\lambda_2 = 2$

A probabilidade de classifição incorreta é dadao por: 
\begin{equation}
P(C_k | C_j, R) = \int_{\chi_k} f_j(x) dx
\end{equation}

Como temos duas classes, para elementos com valor das variáveis preditoras igual a x devem ser classicada em $C_1$ se 

\begin{equation}
\frac{f_1(x)}{f_2(x)} \geq \frac{\pi_2}{\pi_1} = \frac{0,5}{0,5} = 1
\end{equation}
e em $C_2$, caso contrário.

Isto é,
\begin{equation}
\frac{e^{-x}}{2e} \geq 1 \longrightarrow
e^x \geq 2 \longrightarrow
x \geq log2
\end{equation}

Logo, temos que, 
\begin{equation}
\chi_2= [0; log2] \\
\chi_1 = [log2;\infty] \\

\end{equation}
Pela formula de probabilidade de classificação incorreta
\begin{equation}
P(C_1 | C_2; R) = \int^\infty_{log2}2e^{-2x}dx = 0.25\\
P(C_2 | C_1; R) = \int^{log2}_{0}e^{-x}dx = -e^{-log2} - (-e^0 ) = \frac{1}{2} \\

\end{equation}


Criando o gráfico de fronteiras
```{r}


# Gerando os dados de exemplo

# Criando o gráfico
ggplot() +

  geom_vline(xintercept = log(2), linetype = "dashed") +
  geom_text(aes(x = 2, y = 0.5, label = "Classe 1"), hjust = 0, vjust = 0) +
  geom_text(aes(x = 0, y = 0.5, label = "Classe 2"), hjust = 1, vjust = 0) +
  labs(x = "X", y = "Y", title = "Fronteira de Decisão e Origem") +
  xlim(-2, 5)

```

Generalizando, temos que 
\begin{equation}
f(x_1;\lambda_1 = \frac{1}{\alpha})=
\begin{cases}
\frac{1}{\alpha} e^{-\frac{1}{\alpha} x}, & \text{se}\ x_1 \geq 0 \\
0, & \text{caso contrário}
\end{cases}
\\
f(x_2;\lambda_2 = \frac{1}{\beta})=
\begin{cases}
\frac{1}{\beta}e^{-\frac{1}{\beta} x}, & \text{se}\ x_2 \geq 0 \\
0, & \text{caso contrário}
\end{cases}
\end{equation}

Como temos duas classes, para elementos com valor das variáveis preditoras igual a x devem ser classicada em $C_1$ se 

\begin{equation}
\frac{f_1(x)}{f_2(x)} \geq \frac{\pi_2}{\pi_1} = \frac{0,5}{0,5} = 1
\end{equation}


Isto é,
\begin{equation}
\frac{\frac{1}{\alpha} e^{-\frac{1}{\alpha} x}}{\frac{1}{\beta}e^{-\frac{1}{\beta} x}} \geq 1 \longrightarrow
e^{x(\frac{\alpha - \beta}{\alpha\beta})} \geq \frac{\alpha}{\beta} \longrightarrow
x \geq log(\frac{\alpha}{\beta})\frac{\alpha \beta}{\alpha-\beta}
\end{equation} 

Então, temos que 
\begin{equation}
\chi_1 = [log(\frac{\alpha}{\beta})\frac{\alpha \beta}{\alpha-\beta}; \infty] \\
\chi_2 = [0;log(\frac{\alpha}{\beta})\frac{\alpha \beta}{\alpha-\beta}] \\

\end{equation}


Pela formula de probabilidade de classificação incorreta
\begin{equation}
P(C_1 | C_2; R) = \int^\infty_{log(\frac{\alpha}{\beta})\frac{\alpha \beta}{\alpha-\beta}}\frac{1}{\beta}e^{-\frac{1}{\beta} x}dx \\
P(C_2 | C_1; R) = \int^{log(\frac{\alpha}{\beta})\frac{\alpha \beta}{\alpha-\beta}}_{0}\frac{1}{\alpha} e^{-\frac{1}{\alpha} x}dx  \\


\end{equation}

## Item 1b


Simule 200 observações de cada distribuição exponencial da parte (a). Usando os dados para estimar os parâmetros, supostos agora desconhecidos, obtenha o classificador de Bayes, a fronteira de decisão e as probabilidades de classificação incorreta com a regra obtida no exercício anterior. Compare os resultados com aqueles obtidos no item (a).


### Resposta:

Simulando cada distribuição exponecial
```{r}

lamda_1 <- 1
lambda_2 <- 2
n <- 200

amostra_1 <- rexp(n, rate = 1/lamda_1)
amostra_2 <- rexp(n, rate = 1/lambda_2)


```
Vamos assumir que os parâmetros são desconhecidos
Nesse contexto, vamos assumir que $X_j|Y = k  \sim exp(\lambda_i)$. Temos que estmiar a média e variância para cada amostra:

```{r}
media_1 <-  mean(amostra_1)

media_2 <-  mean(amostra_2)

```
Temos que $\mu_1 = `r media_1`$ e $mu_2 = `r media_2`$.
Como temos duas classes, para elementos com valor das variáveis preditoras igual a x devem ser classicada em $C_1$ se 

\begin{equation}
\frac{f_1(x)}{f_2(x)} \geq \frac{\pi_2}{\pi_1} = \frac{0,5}{0,5} = 1 \longrightarrow x \leq 1.3526

\end{equation}


A fronteira de classificação, portanto, é 1.3526
```{r}

```


# Exercício 2

Considere os dados do arquivo `disco` e a variável resposta `y` = 1 se o disco estiver deslocado e `y` = 0, caso contrário. Use a função discriminante linear de Fisher para obter um classificador. Tome o conjunto de treinamento aquele contendo as primeiras 80 observações e o conjunto de teste contendo as demais 24 observações. Obtenha um classificador tendo como variável preditora a distância aberta e outro tendo como preditores as duas distâncias. Use a função `lda()` do pacote `MASS`. Interprete os resultados e escolha o melhor classificador usando a acurácia como base. Obtenha a sensibilidade e especificidade de cada classificador.

### Resposta:
Extraindo o arquivo
```{r }
disco <- readxl::read_excel("disco.xls")
head(disco)
```
Definindo as amostras de treino e teste

```{r}
treino <- disco[1:80,]
teste <- disco[81:104,]
```

Estimando classificador com preditor distância aberta
```{r}
lda_dist_aberta <- lda(deslocamento ~ distanciaA, data = treino)
lda_pred_dist_aberta <- predict(lda_dist_aberta, newdata = teste)
```

Estimando classificador cujas preditoras são as duas distâncias
```{r}
lda_duas_dist <- lda(deslocamento ~ distanciaA + distanciaF, data = treino)
lda_pred_duas_dist <-  predict(lda_duas_dist, newdata = teste)
```


Calculando as taxas de erro dos modelos de distância aberta e com duas distâncias
```{r}
(db <-  teste %>%  
   mutate(deslocamento_pred_dist_aberta = lda_pred_dist_aberta$class,
          erro_pred_dist_aberta = deslocamento_pred_dist_aberta != deslocamento,
          deslocamento_pred_duas_dist = lda_pred_duas_dist$class,
          erro_pred_duas_dist = deslocamento_pred_duas_dist != deslocamento,
          )
 )
taxa_erro_pred_dist_aberta <-  sum(db$erro_pred_dist_aberta)/24
taxa_erro_pred_duas_dist <-  sum(db$erro_pred_duas_dist)/24

```
A taxa de erro do modelo com distância aberta é `r taxa_erro_pred_dist_aberta`;a taxa de erro do modelo com duas distâncias é `r taxa_erro_pred_duas_dist`.



Criando a tabela para lda distância aberta:

```{r}
matriz_dist_aberta <- table(previsao = lda_pred_dist_aberta$class, observado = teste$deslocamento) 

acuracia_dist_aberta <- sum(matriz_dist_aberta[row(matriz_dist_aberta) == col(matriz_dist_aberta)])/ sum(matriz_dist_aberta)
sensibilidade_dist_aberta <- matriz_dist_aberta[1,1]/sum(matriz_dist_aberta[1,1],matriz_dist_aberta[2,1])
especificidade_dist_aberta <- matriz_dist_aberta[2,2]/sum(matriz_dist_aberta[1,2],matriz_dist_aberta[2,2])
matriz_dist_aberta
```
A acurácia do modelo com distância aberta é `r acuracia_dist_aberta`;
a sensibilidade do modelo com distância aberta é `r sensibilidade_dist_aberta`;
a especificidade do modelo com distância aberta é `r especificidade_dist_aberta`.


Criando a tabela para lda de duas distâncias:

```{r}
matriz_duas_dist <- table(previsao = lda_pred_duas_dist$class,observado = teste$deslocamento) 

acuracia_duas_dist <- sum(matriz_duas_dist[row(matriz_duas_dist) == col(matriz_duas_dist)])/ sum(matriz_duas_dist)

sensibilidade_duas_dist<- matriz_duas_dist[1,1]/sum(matriz_duas_dist[row(matriz_duas_dist) == col(matriz_duas_dist)])
especificidade_duas_dist <- matriz_duas_dist[2,2]/sum(matriz_duas_dist[1,2],matriz_duas_dist[2,2])
matriz_duas_dist
```
A acurácia do modelo com duas distâncias é `r acuracia_duas_dist`;
a sensibilidade do modelo com distância aberta é `r sensibilidade_duas_dist`;
a especificidade do modelo com distância aberta é `r especificidade_duas_dist`.

Pelo critério de acúracia, o modelo de duas distâncias é melhor



# Exerício 3

Use o mesmo conjunto de dados do problema anterior e distância aberta como variável preditora. Use LOOCV e o classificador KNN, com vizinhos mais próximos de 1 a 5.

### Reposta:

```{r }

# ajustes na base para estimação

disco <- disco %>% 
  mutate(deslocamento = as.factor(deslocamento))

trControl_loocv <- trainControl(method = "LOOCV")
knn_fit <- train(deslocamento ~ distanciaA, method = "knn",
tuneGrid = expand.grid(k = 1:5),
trControl = trControl_loocv, metric= "Accuracy",
data = disco)
knn_fit
```

## Item 3a

Qual o melhor classificador baseado na acurácia?

### Resposta:
O melhor classsificador, baseado em acuária, é o modelo knn com k = 4.

## Item 3b

Obtenha a matriz de confusão e realize o teste de McNemar.

### Resposta:
```{r}
predict_knn <- predict(knn_fit)
matriz_confusao_tudo <- confusionMatrix(predict_knn, disco$deslocamento)
matriz_confusao <-  matriz_confusao_tudo$table
mcnemars_kkn <- matriz_confusao_tudo[["overall"]][["McnemarPValue"]]

matriz_confusao_tudo
```
A matriz de confusão é `r matriz_confusao`.
A estatística do teste de Mcnemar's é `r mcnemars_kkn`.

## Item 3c

Obtenha a sensibilidade e a especificidade e explique seus significados nesse caso.

### Resposta:

```{r} 
knn_sensitivity <- matriz_confusao_tudo$byClass[1]

knn_specificity <- matriz_confusao_tudo$byClass[2]
```
A sensibilidade é `r knn_sensitivity` e a especificidade é `r knn_specificity`.
Aqui a sensibilidade é uma estimativa das probabilidades de decisões corretas quando o disco realmente não esta deslocado.
A especificidade, por sua vez, é uma estimativa das probabilidades de decisões corretas quando o disco realmente está deslocado


# Exercício 4

O conjunto de dados `Auto` do pacote `ISLR` contém as seguintes variáveis:

-   `mpg`: miles per gallon

-   `cylinders`: Number of cylinders between 4 and 8

-   `displacement`: Engine displacement (cubic inches)

-   `horsepower`: Engine horsepower

-   `weight`: Vehicle weight (lbs.)

-   `acceleration`: Time to accelerate from 0 to 60 mph (sec.)

-   `year`: Model year (modulo 100)

-   `origin`: Origin of car (1. American, 2. European, 3. Japanese)

-   `name`: Vehicle name

## Item 4a

Divida os dados em conjunto de treinamento (`S`) e conjunto de teste (`T`).

### Resposta:
```{r} 
sample <- sample(c(TRUE, FALSE), nrow(Auto), replace=TRUE, prob=c(0.7,0.3))
S  <- Auto[sample, ]
T   <- Auto[!sample, ]
```

## Item 4b

Ajuste um modelo aos dados de `S` tendo `horsepower` como preditor e `mpg` como resposta. Obtenha os EMQ de treinamento e faça o diagnóstico do modelo. O que você nota no gráfico dos resíduos contra valores ajustados? Obtenha o EQM de teste.

### Resposta:
Estimando modelo de EMQ de treinamtno
```{r} 
# EMQ de treinamento
emq_auto <- glm(formula = mpg ~ horsepower, data = S) 
summary(emq_auto)
```


Criando gráfico dos resíduos contra valores ajustados.

```{r}

emq_valores_ajustados <- fitted.values(emq_auto)
emq_residuos <- residuals(emq_auto)

plot(emq_valores_ajustados, emq_residuos, 
     xlab = "Valores Ajustados", 
     ylab = "Resíduos",
     main = "Gráfico de Valores Ajustados vs. Resíduos")
```
O gráfico 

calculando EQM de teste:

```{r}
emq_auto_predict_T <- predict(emq_auto, newdata = T)
```

## Item 4c

Agora inclua $(\text{horsepower})^2$ no modelo e proceda como no item (b). Qual modelo você escolheria? Justifique.

### Resposta:
```{r} 
emq_auto_quadrado <- glm(formula = mpg ~ horsepower + horsepower^2, data = S) 
summary(emq_auto_quadrado)

```
## Item 4d

Ajuste um modelo de regressão ridge aos dados de $S$, tendo `mpg` com resposta e `displacement`, `horsepower`, `weight` e `acceleration` como preditores, com $\lambda$ escolhido por VC. Obtenha o EQM de teste.

### Resposta:

Transformando dataframe em matriz

```{r} 
X_linha <- S[,3:6]
X_linha_matriz <- as.matrix(X_linha)
Y_linha <- as.matrix(S[,1])


```

Estimando o modelo Ridge, plotando o gráfico para efeito da avaliação do efeito do coeficiente de regularização e imprimindo coeficientes.
```{r}
# estimando o modelo ridge
emq_auto_ridge <- cv.glmnet(X_linha_matriz, Y_linha, alpha = 0) 
# plot(emq_auto_ridge)
coef(emq_auto_ridge, s = "lambda.min")
lambda_vc <- emq_auto_ridge$lambda.min
```
O lambda escolhido por VC é `r lambda_vc`.

calculando o EQM.

```{r}
emq_auto_ridge_predict <- predict(emq_auto_ridge, X_linha_matriz, s = "lambda.min")
emq_auto_ridge_eqm <- sqrt(emq_auto_ridge$cvm[emq_auto_ridge$lambda == emq_auto_ridge$lambda.min])
emq_auto_ridge_r2 <- emq_auto_ridge$dev.ratio

```
Temos que o EQM do Ridge é `r emq_auto_ridge_eqm` e o $R^2$ é `r emq_auto_ridge_r2`

## Item 4e

Ajuste um modelo de regressão `lasso` e proceda como em (d). Quais coeficientes foram zerados? Comente sobre os resultados obtidos em (d) e (e), baseados no $R^2$ e $EQMI$.


### Resposta

Estimando o modelo de regerssão lasso e imprimindo os coeficientes.
```{r}

emq_auto_lasso = cv.glmnet(X_linha_matriz, Y_linha, alpha = 1)
coef(emq_auto_lasso, s = "lambda.min")

```
Como se pode notar, o coeficiente de acceleration foi zerado.


Calculando $R^2$ e $EQMI$ do Lasso.
```{r}

emq_auto_lasso_eqm <- sqrt(emq_auto_lasso$cvm[emq_auto_lasso$lambda == emq_auto_lasso$lambda.min])
emq_auto_lasso_r2 <- emq_auto_lasso$dev.ratio


emq_auto_lasso_eqm

emq_auto_lasso_r2
```
Temos que o EQM do lasso é `r emq_auto_lasso_eqm` e o $R^2$ é `r emq_auto_lasso_r2`.
O EQM do Ridge é `r emq_auto_ridge_eqm` e o $R^2$ é `r emq_auto_ridge_r2`
